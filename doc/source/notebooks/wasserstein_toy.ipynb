{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Wasserstein distance estimation\n",
    "\n",
    "In this notebook we estimate the wasserstein distance through its Kantorovich-Rubinestein \n",
    "dual representation by using a 1-Lipschitz neural network by using.\n",
    "\n",
    "\n",
    "## 1. Wasserstein distance\n",
    "\n",
    "The wasserstein distance measure the distance between two probability distributions. \n",
    "The Wikipedia article gives a more intuitive definition of it:\n",
    "\n",
    "> Intuitively, if each distribution is viewed as a unit amount of \"dirt\" piled on {\\displaystyle M}M, the metric is the minimum \"cost\" of turning one pile into the other, which is assumed to be the amount of dirt that needs to be moved times the mean distance it has to be moved. Because of this analogy, the metric is known in computer science as the earth mover's distance.\n",
    "\n",
    "Mathematically it is defined as\n",
    "\n",
    "$$\n",
    "W_1(\\mu,\\nu) = \\inf_{\\pi \\in \\Pi(\\mu,\\nu)}\\underset{x,z \\sim \\pi}{\\mathbb{E}}\\parallel \\textbf{x}-\\textbf{z} \\parallel\\label{wasserstein}\n",
    "$$\n",
    "\n",
    "where $\\Pi(\\mu,\\nu)$ is the set of all probability measures on $\\Omega\\times \\Omega$ with marginals $\\mu$ and $\\nu$. In most case this equation is not tractable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameters input images\n",
    "\n",
    "We illustrate this on a synthetic image dataset where the $W_1$ distance is known.\n",
    "\n",
    "Our synthetic dataset contains images with black or white squares, allowing us to check if the computed \n",
    "wasserstein distance is correct.\n",
    "The two distributions are\n",
    "\n",
    "- the set of black images (all 0),\n",
    "- the set of images with a square on it (all 0, with a square of -1 or +1 in the middle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "size = (64, 64)\n",
    "frac = 0.3  # proportion of the center square\n",
    "\n",
    "\n",
    "def generate_toy_images(shape: Tuple[int, int], frac: float = 0, value: float = 1):\n",
    "    \"\"\"\n",
    "    Function that generate a single image.\n",
    "\n",
    "    Args:\n",
    "        shape: Shape of the output image.\n",
    "        frac: Proportion of the center rectangle.\n",
    "        value: Value assigned to the center rectangle.\n",
    "    \"\"\"\n",
    "    img = np.zeros(shape)\n",
    "    if frac == 0:\n",
    "        return img\n",
    "\n",
    "    frac = frac ** 0.5\n",
    "\n",
    "    l = int(shape[0] * frac)\n",
    "    ldec = (shape[0] - l) // 2\n",
    "    w = int(shape[1] * frac)\n",
    "    wdec = (shape[1] - w) // 2\n",
    "\n",
    "    img[ldec : ldec + l, wdec : wdec + w] = value\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def generator(batch_size: int, shape: Tuple[int, int], frac: float):\n",
    "    \"\"\"\n",
    "    Creates an infinite generator that generates batch of images. Half of the batch\n",
    "    comes from the first distribution (only black images), while the remaining half\n",
    "    comes from the second distribution.\n",
    "\n",
    "    Args:\n",
    "        batch_size: Number of images in each batch.\n",
    "        shape: Shape of the image.\n",
    "        frac: Fraction of the square to set \"white\".\n",
    "\n",
    "    Returns:\n",
    "        An infinite generator that yield batch of the given size.\n",
    "    \"\"\"\n",
    "\n",
    "    pwhite = generate_toy_images(shape, frac=frac, value=1)\n",
    "    nwhite = generate_toy_images(shape, frac=frac, value=-1)\n",
    "\n",
    "    nblack = batch_size // 2\n",
    "    nsquares = batch_size - nblack\n",
    "    npwhite = nsquares // 2\n",
    "    nnwhite = nsquares - npwhite\n",
    "\n",
    "    batch_x = np.concatenate(\n",
    "        (\n",
    "            np.zeros((nblack,) + shape),\n",
    "            np.repeat(pwhite[None, ...], npwhite, axis=0),\n",
    "            np.repeat(nwhite[None, ...], nnwhite, axis=0),\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    batch_y = np.concatenate((np.zeros((nblack, 1)), np.ones((nsquares, 1))), axis=0)\n",
    "\n",
    "    while True:\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "\n",
    "def display_image(ax, image, title: str = \"\"):\n",
    "    \"\"\"\n",
    "    Small function to display images.\n",
    "    \"\"\"\n",
    "    ax.imshow(image, cmap=\"gray\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider images of size $64\\times{}64$, and an inner square that covers about 30% of the image. \n",
    "We can manually compute the $W_1$ distance between the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2-Norm, black vs. 'negative' white -> 35.0\n",
      "L2-Norm, black vs. 'positive' white -> 35.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1512x504 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = generate_toy_images(size, 0)\n",
    "img2 = generate_toy_images(size, frac, value=-1)\n",
    "img3 = generate_toy_images(size, frac, value=1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7))\n",
    "\n",
    "display_image(axs[0], img1, \"black (label = -1)\")\n",
    "display_image(axs[1], img2, \"'negative' white (label = 1)\")\n",
    "display_image(axs[2], img3, \"'positive' white (label = 1)\")\n",
    "\n",
    "print(\"L2-Norm, black vs. 'negative' white -> {}\".format(np.linalg.norm(img2 - img1)))\n",
    "print(\"L2-Norm, black vs. 'positive' white -> {}\".format(np.linalg.norm(img3 - img1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the distance between the fully black image and any of the two images with an inner square is $35$, and see these are the only images in our distributions, the $W_1$ distance between the two distances is also $35$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kantorovich-Rubinestein dual formulation\n",
    "\n",
    "The Kantorovich-Rubinestein (KR) dual formulation of the Wasserstein distance is\n",
    "\n",
    "$$ W_1(\\mu, \\nu) = \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] -\\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right]. $$\n",
    "\n",
    "This state the problem as an optimization problem over the space of 1-Lipschitz functions.\n",
    "We can estimate this by optimizing over the space of 1-Lipschitz neural networks.\n",
    "\n",
    "- [1] C. Anil, J. Lucas, et R. Grosse, « Sorting out Lipschitz function approximation », arXiv:1811.05381 [cs, stat], nov. 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Building lipschitz Model\n",
    "\n",
    "In this section, we use the `deel.torchlip` (short `torchlip`) to build a 1-Lipschitz network.\n",
    "The `torchlip` library is the PyTorch equivalent of [`deel-lip`](https://github.com/deel-ai/deel-lip).\n",
    "In this example, we use two 1-Lipschitz layers and a special activation function:\n",
    "\n",
    "- `SpectralLinear` uses spectral normalization to force the maximum singular value of the weight matrix to be one, followed by Bjorck normalization to force all singular values to be 1. After convergence, all singular values are equal to 1 and the linear operation is 1-Lipschitz. The `SpectralLinear` class also uses orthogonal initialization for the weight (see `torch.init.orthogonal_`).\n",
    "- `FrobeniusLinear` simply divide the weight matrix by its Frobenius norm. We only use it for the last layer because this layer has a single output. Similar to `SpectralLinear`, the weights are initialized using orthogonal initialization.\n",
    "- We use `FullSort` activation, which is a 1-Lipschitz activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential model contains a layer which is not a Lipschitz layer: Flatten(start_dim=1, end_dim=-1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): SpectralLinear(in_features=4096, out_features=128, bias=True)\n",
       "  (2): FullSort()\n",
       "  (3): SpectralLinear(in_features=128, out_features=64, bias=True)\n",
       "  (4): FullSort()\n",
       "  (5): SpectralLinear(in_features=64, out_features=32, bias=True)\n",
       "  (6): FullSort()\n",
       "  (7): FrobeniusLinear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from deel import torchlip\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "wass = torchlip.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torchlip.SpectralLinear(np.prod(size), 128),\n",
    "    torchlip.FullSort(),\n",
    "    torchlip.SpectralLinear(128, 64),\n",
    "    torchlip.FullSort(),\n",
    "    torchlip.SpectralLinear(64, 32),\n",
    "    torchlip.FullSort(),\n",
    "    torchlip.FrobeniusLinear(32, 1),\n",
    ").to(device)\n",
    "\n",
    "wass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Training a 1-Lipschitz network with KR loss\n",
    "\n",
    "We now train this neural network using the Kantorovich-Rubinestein formulation for the Wasserstein distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3523236ef74938898bcf7522f2d7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe317a702f64fadb9440026c850b7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from deel.torchlip.functional import kr_loss\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "batch_size = 16\n",
    "n_epochs = 10\n",
    "steps_per_epoch = 256\n",
    "\n",
    "# Create the image generator:\n",
    "g = generator(batch_size, size, frac)\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=0.01, params=wass.parameters())\n",
    "\n",
    "n_steps = steps_per_epoch // batch_size\n",
    "tepochs = trange(n_epochs)\n",
    "tsteps = trange(n_steps)\n",
    "\n",
    "for epoch in tepochs:\n",
    "    tsteps.reset()\n",
    "    for _ in range(n_steps):\n",
    "        data, target = next(g)\n",
    "        data, target = (\n",
    "            torch.tensor(data).float().to(device),\n",
    "            torch.tensor(target).float().to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        output = wass(data)\n",
    "        loss = kr_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tsteps.set_postfix({\"loss\": \"{:.6f}\".format(loss)})\n",
    "        tsteps.update()\n",
    "    tsteps.refresh()\n",
    "    tepochs.set_postfix({\"loss\": \"{:.6f}\".format(loss)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the loss converge to the value $35$ which is the $W_1$ distance between the two distributions (with and without squares)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}